{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_origin, y_train_origin),(x_test_origin, y_test_origin) = mnist.load_data()\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_origin.reshape((60000, 28 * 28))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test_origin.reshape((10000, 28 * 28))\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_origin, num_classes=10) \n",
    "y_test = to_categorical(y_test_origin, num_classes=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(dim):\n",
    "    # w = feature * class\n",
    "    # b = 1 * class\n",
    "    w = np.zeros((dim, 10))\n",
    "    b = np.zeros((1, 10))\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the reference for softmax: (https://segmentfault.com/a/1190000010039529)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute the softmax function for each row of the input x.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A N dimensional vector or M x N dimensional numpy matrix.\n",
    "\n",
    "    Return:\n",
    "    x -- You are allowed to modify x in-place\n",
    "    \"\"\"\n",
    "    orig_shape = x.shape\n",
    "\n",
    "    if len(x.shape) > 1:\n",
    "        # Matrix\n",
    "        exp_minmax = lambda x: np.exp(x - np.max(x))\n",
    "        denom = lambda x: 1.0 / np.sum(x)\n",
    "        x = np.apply_along_axis(exp_minmax,1,x)\n",
    "        denominator = np.apply_along_axis(denom,1,x) \n",
    "        \n",
    "        if len(denominator.shape) == 1:\n",
    "            denominator = denominator.reshape((denominator.shape[0],1))\n",
    "        \n",
    "        x = x * denominator\n",
    "    else:\n",
    "        # Vector\n",
    "        x_max = np.max(x)\n",
    "        x = x - x_max\n",
    "        numerator = np.exp(x)\n",
    "        denominator =  1.0 / np.sum(numerator)\n",
    "        x = numerator.dot(denominator)\n",
    "        \n",
    "    assert x.shape == orig_shape\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    A = softmax((np.dot(X,w)) + b)\n",
    "    cost  = -1/m * np.sum(Y*np.log(A))\n",
    "    dw = -1/m * np.dot(X.T, (Y-A))\n",
    "    db = -1/m * np.sum(Y-A)\n",
    "    \n",
    "    \n",
    "    grads = {\"dw\":dw, \"db\": db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iters, batch_size, learning_rate, print_cost):\n",
    "    \n",
    "    costs = []\n",
    "    m = X.shape[0]\n",
    "    for i in range(num_iters):\n",
    "        #cost_batch is used to collect the cost during one iteration over different batches\n",
    "        cost_batch = []\n",
    "        #stochastic gradient descent\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_shuffled = X[shuffled_indices,:]\n",
    "        y_shuffled = Y[shuffled_indices,:]\n",
    "        #mini-batch\n",
    "        for j in range(0, m, batch_size):\n",
    "            x_batch = X_shuffled[j:j+batch_size,:]\n",
    "            y_batch = y_shuffled[j:j+batch_size,:]\n",
    "            grads, cost = propagate(w, b, x_batch, y_batch)\n",
    "            dw = grads['dw']\n",
    "            db = grads['db']\n",
    "            \n",
    "            w = w - learning_rate * dw\n",
    "            b = b - learning_rate * db\n",
    "\n",
    "            cost_batch.append(cost)\n",
    "            # the cost of one iteration is the average number over batches\n",
    "            cost = np.mean(cost_batch)\n",
    "        costs.append(cost)\n",
    "        \n",
    "        if print_cost:\n",
    "            print(\"Cost after iteration %i: %f\" % (i+1, cost))\n",
    "\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    return softmax((np.dot(X, w) + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, Y):\n",
    "    \n",
    "    max_index = np.argmax(y_hat, axis=1)\n",
    "    y_hat[np.arange(y_hat.shape[0]), max_index] = 1\n",
    "    accuracy = np.sum(np.argmax(y_hat, axis=1)==np.argmax(Y, axis=1))   \n",
    "    accuracy = accuracy *1.0/Y.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test, num_iters=20, batch_size = 5, learning_rate=0.5, print_cost=False):\n",
    "    \n",
    "    w, b = init_params(x_train.shape[1])\n",
    "    \n",
    "    parameters, grads, costs = optimize(w, b, x_train, y_train, num_iters, batch_size, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters['w']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    \n",
    "    y_pred_test = predict(w, b, x_test)\n",
    "    y_pred_train = predict(w, b, x_train)\n",
    "    \n",
    "    train_accuracy = accuracy(y_pred_train, y_train)\n",
    "    test_accuracy = accuracy(y_pred_test, y_test)\n",
    "    \n",
    "    print(\"train accuracy: {} %\".format(100*train_accuracy))\n",
    "    print(\"test accuracy: {} %\".format(100*test_accuracy))\n",
    "    \n",
    "    \n",
    "    d = {\n",
    "        'w':w,\n",
    "        'b':b,\n",
    "        'costs':costs,\n",
    "        'Y_pred_test': y_pred_test, \n",
    "        'Y_pred_train' : y_pred_train, \n",
    "        'iterations':num_iters,\n",
    "        'learning_rate':learning_rate,\n",
    "        'num_iters': num_iters}\n",
    "    return d, train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 1: 2.030298\n",
      "Cost after iteration 2: 1.616022\n",
      "Cost after iteration 3: 1.350116\n",
      "Cost after iteration 4: 1.173601\n",
      "Cost after iteration 5: 1.050627\n",
      "Cost after iteration 6: 0.960783\n",
      "Cost after iteration 7: 0.892426\n",
      "Cost after iteration 8: 0.838652\n",
      "Cost after iteration 9: 0.795176\n",
      "Cost after iteration 10: 0.759242\n",
      "train accuracy: 84.62166666666666 %\n",
      "test accuracy: 85.64 %\n"
     ]
    }
   ],
   "source": [
    "d, train, test = model(x_train, y_train, x_test, y_test, num_iters=10, batch_size=1000, learning_rate=0.01, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
